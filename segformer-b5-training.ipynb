{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!cp -r ../input/pytorch-segmentation-models-lib/ ./\n!cp -r ../input/torchmetrics/ ./\n\n!pip config set global.disable-pip-version-check true\n\n!pip install -q ./pytorch-segmentation-models-lib/pretrainedmodels-0.7.4/pretrainedmodels-0.7.4\n!pip install -q ./pytorch-segmentation-models-lib/efficientnet_pytorch-0.6.3/efficientnet_pytorch-0.6.3\n!pip install -q ./pytorch-segmentation-models-lib/timm-0.4.12-py3-none-any.whl\n!pip install -q ./pytorch-segmentation-models-lib/segmentation_models_pytorch-0.2.0-py3-none-any.whl\n!pip install -q ./torchmetrics/torchmetrics-0.9.1-py3-none-any.whl","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:52:04.272625Z","iopub.execute_input":"2022-09-07T04:52:04.274091Z","iopub.status.idle":"2022-09-07T04:53:07.131614Z","shell.execute_reply.started":"2022-09-07T04:52:04.273385Z","shell.execute_reply":"2022-09-07T04:53:07.130233Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### https://arxiv.org/pdf/2105.15203.pdf","metadata":{}},{"cell_type":"markdown","source":"## Library imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\n\nimport os\nimport json\nfrom tqdm.auto import tqdm\nimport gc\n\nfrom skimage import io\nfrom skimage.transform import resize\n\nimport matplotlib.pyplot as plt\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Trainer\n\nimport segmentation_models_pytorch as smp\nfrom torchmetrics.functional import dice\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom operator import itemgetter \nimport os\nos.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:53:07.134294Z","iopub.execute_input":"2022-09-07T04:53:07.134716Z","iopub.status.idle":"2022-09-07T04:53:13.071336Z","shell.execute_reply.started":"2022-09-07T04:53:07.134670Z","shell.execute_reply":"2022-09-07T04:53:13.070063Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n!pip install spams\n!pip install staintools\n\nimport pathlib\nimport numpy as np\nimport cv2\nimport tifffile\nimport matplotlib.pyplot as plt\nimport staintools\n\nimport gc\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport pytorch_lightning as pl\nfrom pytorch_lightning import Trainer\n\nimport segmentation_models_pytorch as smp\nfrom torchmetrics.functional import dice\n\n\nfrom operator import itemgetter \n\nimport pandas as pd\nfrom transformers import BertTokenizer, BertModel\nfrom torch.optim import lr_scheduler\nfrom torch import nn\nfrom torch.optim import Adam\nfrom tqdm.notebook import tqdm","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:53:13.078062Z","iopub.execute_input":"2022-09-07T04:53:13.081278Z","iopub.status.idle":"2022-09-07T04:55:16.026058Z","shell.execute_reply.started":"2022-09-07T04:53:13.081230Z","shell.execute_reply":"2022-09-07T04:55:16.024953Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"imaging_measurements = {\n    'hpa': {\n        'pixel_size': {\n            'kidney': 0.4,\n            'prostate': 0.4,\n            'largeintestine': 0.4,\n            'spleen': 0.4,\n            'lung': 0.4\n        },\n        'tissue_thickness': {\n            'kidney': 4,\n            'prostate': 4,\n            'largeintestine': 4,\n            'spleen': 4,\n            'lung': 4\n        }\n    },\n    'hubmap': {\n        'pixel_size': {\n            'kidney': 0.5,\n            'prostate': 6.263,\n            'largeintestine': 0.229,\n            'spleen': 0.4945,\n            'lung': 0.7562\n        },\n        'tissue_thickness': {\n        'kidney': 10,\n            'prostate': 5,\n            'largeintestine': 8,\n            'spleen': 4,\n            'lung': 5\n        }\n    }\n}","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:55:16.029486Z","iopub.execute_input":"2022-09-07T04:55:16.030225Z","iopub.status.idle":"2022-09-07T04:55:16.040495Z","shell.execute_reply.started":"2022-09-07T04:55:16.030177Z","shell.execute_reply":"2022-09-07T04:55:16.039583Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def augment_image(image, domain_pixel_size, target_pixel_size, domain_tissue_thickness, target_tissue_thickness, alpha=0.15):\n    \n    \n    # Augment tissue thickness\n    tissue_thickness_scale_factor = target_tissue_thickness - domain_tissue_thickness\n    image_hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV).astype(np.float32)\n    image_hsv[:, :, 1] *= (1 + (alpha * tissue_thickness_scale_factor))\n    image_hsv[:, :, 2] *= (1 - (alpha * tissue_thickness_scale_factor))\n    image_hsv = image_hsv.astype(np.uint8)\n    image_scaled = cv2.cvtColor(image_hsv, cv2.COLOR_HSV2RGB)\n    \n    # Standardize luminosity\n    image_scaled = staintools.LuminosityStandardizer.standardize(image_scaled)\n\n    # Augment pixel size\n    pixel_size_scale_factor = domain_pixel_size / target_pixel_size\n    image_resized = cv2.resize(\n        image_scaled,\n        dsize=None,\n        fx=pixel_size_scale_factor,\n        fy=pixel_size_scale_factor,\n        interpolation=cv2.INTER_CUBIC\n    )\n    \n    image_resized = cv2.resize(\n        image_resized,\n        dsize=(\n            image.shape[1],\n            image.shape[0]\n        ),\n        interpolation=cv2.INTER_CUBIC\n    )\n    \n    # Standardize luminosity\n    \n    from random import randrange\n    num = randrange(10)\n    \n    \n    \n    image = staintools.LuminosityStandardizer.standardize(image)\n    image_augmented = staintools.LuminosityStandardizer.standardize(image_resized)\n    \n    returnImage = image\n    if(num <5):\n        returnImage = image_augmented\n    \n    del image_scaled\n    del image_resized\n    del image\n    del image_augmented\n    del image_hsv\n    gc.collect()\n    \n    return returnImage","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:55:16.042089Z","iopub.execute_input":"2022-09-07T04:55:16.043109Z","iopub.status.idle":"2022-09-07T04:55:16.053995Z","shell.execute_reply.started":"2022-09-07T04:55:16.043071Z","shell.execute_reply":"2022-09-07T04:55:16.052699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Paths definition","metadata":{}},{"cell_type":"code","source":"TRAIN_IMG_PATH = \"../input/hubmap-organ-segmentation/train_images\"\nTEST_IMG_PATH = \"../input/hubmap-organ-segmentation/test_images\"\n\nTRAIN_IMG_ANNOTATIONS = \"../input/hubmap-organ-segmentation/train_annotations\"\nTRAIN_IMG_INFO = \"../input/hubmap-organ-segmentation/train.csv\"","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:55:16.055737Z","iopub.execute_input":"2022-09-07T04:55:16.056479Z","iopub.status.idle":"2022-09-07T04:55:16.068597Z","shell.execute_reply.started":"2022-09-07T04:55:16.056441Z","shell.execute_reply":"2022-09-07T04:55:16.067569Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Auxiliary functions","metadata":{}},{"cell_type":"code","source":"def rle2mask(mask_rle: str, shape=None, label: int = 0):\n    \"\"\"\n    mask_rle: run-length as string formatted (start length)\n    shape: (height,width) of array to return\n    Returns numpy array, 1 - mask, 0 - background\n\n    \"\"\"\n    rle = np.array(list(map(int, mask_rle.split())))\n    labels = np.zeros(shape).flatten()\n    \n    for start, end in zip(rle[::2], rle[1::2]):\n        labels[start:start+end] = label\n\n    return labels.reshape(shape).T  # Needed to align to RLE direction\n\n\ndef mask_to_rle(mask):\n    #Rescale image to original size\n    size = int(len(mask.flatten())**.5)\n    n = Image.fromarray(mask.reshape((size, size))*255.0)\n    n = np.array(n).astype(np.float32)\n    #Get pixels to flatten\n    pixels = n.T.flatten()\n    #Round the pixels using the half of the range of pixel value\n    pixels = (pixels-min(pixels) > ((max(pixels)-min(pixels))/2)).astype(int)\n    pixels = np.nan_to_num(pixels) #incase of zero-div-error\n    \n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0]\n    runs[1::2] -= runs[::2]\n    \n    return ' '.join(str(x) for x in runs)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:55:16.070559Z","iopub.execute_input":"2022-09-07T04:55:16.071638Z","iopub.status.idle":"2022-09-07T04:55:16.082281Z","shell.execute_reply.started":"2022-09-07T04:55:16.071594Z","shell.execute_reply":"2022-09-07T04:55:16.081301Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Reading training dataframe","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(TRAIN_IMG_INFO)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:55:16.084074Z","iopub.execute_input":"2022-09-07T04:55:16.084892Z","iopub.status.idle":"2022-09-07T04:55:16.391428Z","shell.execute_reply.started":"2022-09-07T04:55:16.084856Z","shell.execute_reply":"2022-09-07T04:55:16.390439Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_train.head(2)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:55:16.392935Z","iopub.execute_input":"2022-09-07T04:55:16.393346Z","iopub.status.idle":"2022-09-07T04:55:16.417290Z","shell.execute_reply.started":"2022-09-07T04:55:16.393306Z","shell.execute_reply":"2022-09-07T04:55:16.416495Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"organs = df_train['organ'].unique()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:55:16.421160Z","iopub.execute_input":"2022-09-07T04:55:16.421852Z","iopub.status.idle":"2022-09-07T04:55:16.432055Z","shell.execute_reply.started":"2022-09-07T04:55:16.421817Z","shell.execute_reply":"2022-09-07T04:55:16.431115Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"organ_annotations = {}\n\nfor i, organ in enumerate(organs):\n    organ_annotations[organ] = i+1\n    \norgan_annotations","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:55:16.435569Z","iopub.execute_input":"2022-09-07T04:55:16.435841Z","iopub.status.idle":"2022-09-07T04:55:16.445879Z","shell.execute_reply.started":"2022-09-07T04:55:16.435816Z","shell.execute_reply":"2022-09-07T04:55:16.444914Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Network training config","metadata":{}},{"cell_type":"code","source":"class Config:\n    BATCH_SIZE = 4\n    EPOCHS = 10","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:55:16.447614Z","iopub.execute_input":"2022-09-07T04:55:16.448077Z","iopub.status.idle":"2022-09-07T04:55:16.454173Z","shell.execute_reply.started":"2022-09-07T04:55:16.448043Z","shell.execute_reply":"2022-09-07T04:55:16.453185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scheduler","metadata":{}},{"cell_type":"code","source":"class PeakScheduler(torch.optim.lr_scheduler._LRScheduler):\n        def __init__(\n                self, optimizer,\n                epoch_size=-1,\n                lr_start   = 0.000001,\n                lr_max     = 0.000005 * Config.BATCH_SIZE,\n                lr_min     = 0.000001,\n                lr_ramp_ep = 4,\n                lr_sus_ep  = 0,\n                lr_decay   = 0.8,\n                verbose = True\n            ):\n            self.epoch_size = epoch_size\n            self.optimizer= optimizer\n            self.lr_start = lr_start\n            self.lr_max = lr_max\n            self.lr_min = lr_min\n            self.lr_ramp_ep = lr_ramp_ep\n            self.lr_sus_ep = lr_sus_ep\n            self.lr_decay = lr_decay\n            self.is_plotting = True\n            \n            epochs = list(range(Config.EPOCHS))\n            learning_rates = []\n            for i in epochs:\n                self.epoch = i\n                learning_rates.append(self.get_lr())\n            self.is_plotting = False\n            self.epoch = 0\n            plt.scatter(epochs,learning_rates)\n            plt.show()\n            super(PeakScheduler, self).__init__(optimizer, verbose=verbose)\n\n        def get_lr(self):\n            if not self.is_plotting:\n                if self.epoch_size == -1:\n                    self.epoch = self._step_count - 1\n                else:\n                    self.epoch = (self._step_count - 1) / self.epoch_size\n                    \n            if self.epoch < self.lr_ramp_ep:\n                lr = (self.lr_max - self.lr_start) / self.lr_ramp_ep * self.epoch + self.lr_start\n\n            elif self.epoch < self.lr_ramp_ep + self.lr_sus_ep:\n                lr = self.lr_max\n            else:\n                lr = (self.lr_max - self.lr_min) * self.lr_decay**(self.epoch - self.lr_ramp_ep - self.lr_sus_ep) + self.lr_min\n            return [lr for _ in self.optimizer.param_groups]\n","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:55:16.455671Z","iopub.execute_input":"2022-09-07T04:55:16.456170Z","iopub.status.idle":"2022-09-07T04:55:16.469379Z","shell.execute_reply.started":"2022-09-07T04:55:16.456134Z","shell.execute_reply":"2022-09-07T04:55:16.468312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Hugging face model","metadata":{}},{"cell_type":"code","source":"from transformers import SegformerForSemanticSegmentation","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:55:16.470989Z","iopub.execute_input":"2022-09-07T04:55:16.471399Z","iopub.status.idle":"2022-09-07T04:55:16.487102Z","shell.execute_reply.started":"2022-09-07T04:55:16.471366Z","shell.execute_reply":"2022-09-07T04:55:16.484411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\n\nimgs = []\n\nfor i, img in enumerate(tqdm(os.listdir(TRAIN_IMG_PATH))):\n    \n    imgs.append(os.path.join(TRAIN_IMG_PATH, img))","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:55:16.488710Z","iopub.execute_input":"2022-09-07T04:55:16.489759Z","iopub.status.idle":"2022-09-07T04:55:16.557404Z","shell.execute_reply.started":"2022-09-07T04:55:16.489724Z","shell.execute_reply":"2022-09-07T04:55:16.556527Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img_size = 512\n\nclass CustomDataset(Dataset):\n    def __init__(self, imgs, df, stage):\n        self.imgs = imgs\n        \n        self.df = df\n        #print(df)\n        #print(df[df['id'] == 28052]['rle'].values[0])\n        mean=[196.869/255, 190.186/255, 194.802/255],\n        std=[63.01/255, 66.765/255, 65.745/255],\n        if stage == 'train':\n            self.transforms = A.Compose([\n                A.augmentations.crops.RandomResizedCrop(height=img_size, width=img_size),\n                A.augmentations.Rotate(limit=90, p=0.5),\n                A.augmentations.HorizontalFlip(p=0.5),\n                A.augmentations.VerticalFlip(p=0.5),\n                A.augmentations.transforms.ColorJitter(p=0.5),\n            \n                A.OneOf([\n                    A.HueSaturationValue(10, 15, 10),\n                    A.CLAHE(clip_limit=4),\n                    A.RandomBrightnessContrast(),            \n                ], p=0.5),                \n                A.Normalize(mean=mean, std=std, max_pixel_value=255),\n            ])\n        else:\n            self.transforms = A.Compose([\n                A.Resize(img_size, img_size),\n                A.Normalize(mean=mean, std=std, max_pixel_value=255),\n            ])\n            \n        \n        \n    def __len__(self):\n        return len(self.imgs)\n    \n    def __getitem__(self, idx):\n        \n        \n        img = self.imgs[idx]\n        img_number = int(img.split(\"/\")[-1].split(\".\")[0])\n        rle = self.df[self.df['id'] == img_number]['rle'].values[0]\n        height = self.df[self.df['id'] == img_number]['img_height'].values[0]\n        width = self.df[self.df['id'] == img_number]['img_width'].values[0]\n        organ = self.df[self.df['id'] == img_number]['organ'].values[0]\n        \n        \n        \n        img = np.asarray(Image.open(img))\n        \n        image_augmented = augment_image(\n            image=img,\n            domain_pixel_size= imaging_measurements['hpa']['pixel_size'][organ],\n            target_pixel_size=imaging_measurements['hubmap']['pixel_size'][organ],\n            domain_tissue_thickness=imaging_measurements['hpa']['tissue_thickness'][organ],\n            target_tissue_thickness=imaging_measurements['hubmap']['tissue_thickness'][organ]\n        )\n     \n        img = image_augmented\n        \n        \n        \n        \n        mask = rle2mask(rle, shape=(height, width), label=organ_annotations[organ])\n        \n        transformed = self.transforms(image=img, mask=np.expand_dims(mask, axis=2))\n        \n        del mask\n        del image_augmented\n        del img\n        gc.collect()\n        \n        return np.transpose(transformed['image'], (2, 0, 1)).astype(np.float32), np.squeeze(transformed['mask'], 2).astype(np.int16)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:57:07.968855Z","iopub.execute_input":"2022-09-07T04:57:07.969269Z","iopub.status.idle":"2022-09-07T04:57:07.984985Z","shell.execute_reply.started":"2022-09-07T04:57:07.969236Z","shell.execute_reply":"2022-09-07T04:57:07.983937Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SegmentationModel(pl.LightningModule):\n    def __init__(\n        self,\n        model\n        ):\n        super(SegmentationModel, self).__init__()\n        \n        self.model = model\n        \n        \n    def forward(self, image):\n        outputs = self.model(pixel_values=image)\n        \n        upsampled_logits = nn.functional.interpolate(\n            outputs.logits,\n            size=mask.shape[-2:], \n            mode=\"bilinear\",\n            align_corners=False\n        )\n#         del outputs\n#         del image\n        gc.collect()\n        \n        return upsampled_logits\n        \n\n    def training_step(self, batch, batch_idx):\n        image, mask = batch[0], batch[1]\n        outputs = self.model(pixel_values=image, labels=mask.long())\n        \n        upsampled_logits = nn.functional.interpolate(\n            outputs.logits,\n            size=mask.shape[-2:], \n            mode=\"bilinear\",\n            align_corners=False\n        )\n        \n        loss = outputs.loss\n        \n#         del outputs\n#         del image\n        gc.collect()\n        \n        return {'loss': loss, 'logits_mask': upsampled_logits, 'mask': mask}\n    \n#     def training_epoch_end(self, outputs):\n#         loss = [item['loss'].item() for item in outputs]\n#         logits_mask = torch.cat([item['logits_mask'].cpu() for item in outputs]).softmax(1)\n#         mask = torch.cat([item['mask'].cpu() for item in outputs])\n        \n#         pred_mask = logits_mask.argmax(dim=1).float()\n        \n#         dice_score = dice(\n#             logits_mask, \n#             mask\n#         ).item()\n        \n#         log_parameters = {\n#             \"loss_train\": np.mean(loss),\n#             \"dice_score_train\": dice_score\n#         }\n        \n#         print(log_parameters)\n        \n#         del outputs\n#         gc.collect()\n        \n#         self.log_dict(log_parameters)\n    \n    def validation_step(self, batch, batch_idx):\n        image, mask = batch[0], batch[1]\n        outputs = self.model(pixel_values=image, labels=mask.long())\n        \n        upsampled_logits = nn.functional.interpolate(\n            outputs.logits,\n            size=mask.shape[-2:], \n            mode=\"bilinear\",\n            align_corners=False\n        )\n        \n        loss = outputs.loss\n        \n        del outputs\n        del image\n        gc.collect()\n        \n        return {'loss': loss, 'logits_mask': upsampled_logits, 'mask': mask}\n        \n    def validation_epoch_end(self, outputs):\n        loss = torch.from_numpy(np.array([item['loss'].item() for item in outputs]))\n        logits_mask = torch.cat([item['logits_mask'].cpu() for item in outputs]).softmax(1)\n        mask = torch.cat([item['mask'].cpu() for item in outputs]).long()\n        \n        pred_mask = logits_mask.argmax(dim=1).long()\n        \n        dice_score = dice(\n            logits_mask, \n            mask\n        ).item()\n        \n        log_parameters = {\n            \"loss_valid\": torch.mean(loss),\n            \"dice_score_valid\": dice_score\n        }\n        \n        del outputs\n        gc.collect()\n        \n        self.log_dict(log_parameters)        \n\n    def configure_optimizers(self):\n        optimizer = torch.optim.Adam(self.parameters(), lr=1e-3)\n        scheduler = PeakScheduler(\n            optimizer,\n            lr_ramp_ep=int(Config.EPOCHS * 0.3), \n            lr_decay=0.95,\n            lr_max=1e-03,\n            lr_min=1e-08\n        )\n        \n        return {\n            \"optimizer\": optimizer,\n            \"lr_scheduler\": {\"scheduler\": scheduler, \"interval\": \"epoch\", \"frequency\": 1}\n        }","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:55:16.582991Z","iopub.execute_input":"2022-09-07T04:55:16.583382Z","iopub.status.idle":"2022-09-07T04:55:16.601531Z","shell.execute_reply.started":"2022-09-07T04:55:16.583348Z","shell.execute_reply":"2022-09-07T04:55:16.600579Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"kf = KFold(n_splits=3, shuffle=True, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:55:16.605275Z","iopub.execute_input":"2022-09-07T04:55:16.605551Z","iopub.status.idle":"2022-09-07T04:55:16.614736Z","shell.execute_reply.started":"2022-09-07T04:55:16.605505Z","shell.execute_reply":"2022-09-07T04:55:16.613883Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fold = 1\ntorch.cuda.empty_cache()\nfor train_idx, test_idx in tqdm(kf.split(range(len(imgs)))):\n    train_imgs = itemgetter(*train_idx)(imgs)\n    valid_imgs = itemgetter(*test_idx)(imgs)\n    \n    train_dataset = CustomDataset(train_imgs, df_train, 'train')\n    valid_dataset = CustomDataset(valid_imgs, df_train, 'valid')\n\n    train_dataloader = DataLoader(train_dataset, batch_size=Config.BATCH_SIZE, shuffle=True, drop_last=False)\n    valid_dataloader = DataLoader(valid_dataset, batch_size=Config.BATCH_SIZE, shuffle=False, drop_last=False)\n    \n    net = SegformerForSemanticSegmentation.from_pretrained(\n        \"nvidia/mit-b5\",\n        ignore_mismatched_sizes=True, \n        num_labels=len(organ_annotations)+1, \n        reshape_last_stage=True\n    )\n    \n    trainer = Trainer(\n        max_epochs=Config.EPOCHS,\n        accelerator=\"cuda\",\n        gpus=1,\n        precision=32, \n        auto_lr_find=True,\n        accumulate_grad_batches=4,\n        auto_scale_batch_size=True,\n        check_val_every_n_epoch=5\n    )\n\n    model = SegmentationModel(net)\n\n    trainer.fit(\n        model,\n        train_dataloader,\n        valid_dataloader,\n\n    )\n    \n    MODEL_NAME = f\"Segformer-fold-{fold}-epochs-{Config.EPOCHS}\"\n\n    if not os.path.exists(os.path.join(\"./\", MODEL_NAME)):\n        os.mkdir(os.path.join(\"./\", MODEL_NAME))\n\n    model.model.save_pretrained(f\"./{MODEL_NAME}\")  \n    \n    fold += 1\n    \n    break","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:57:17.144270Z","iopub.execute_input":"2022-09-07T04:57:17.145303Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import gc\ngc.collect()\ntorch.cuda.empty_cache()","metadata":{"execution":{"iopub.status.busy":"2022-09-07T04:28:30.113696Z","iopub.execute_input":"2022-09-07T04:28:30.114069Z","iopub.status.idle":"2022-09-07T04:28:30.291786Z","shell.execute_reply.started":"2022-09-07T04:28:30.114039Z","shell.execute_reply":"2022-09-07T04:28:30.290727Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### You may try to create an inference notebook by yourself or wait a little bit. I will add it to the public! Even with test-time augmentations ;)","metadata":{}},{"cell_type":"markdown","source":"### Segformer model with mit-b5 backbone, 3 folds gave me 0.70 Dice score on a public LB.","metadata":{}},{"cell_type":"markdown","source":"### If you find this notebook useful, please upvote it.","metadata":{}},{"cell_type":"markdown","source":"### If you have any questions, feel free to start discussions in comments =)","metadata":{}},{"cell_type":"markdown","source":"#### >>> Work is in progress. Notebook will be updated!","metadata":{}},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}